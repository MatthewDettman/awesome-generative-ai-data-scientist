# Awesome Generative AI (LLMs) [![Awesome](https://awesome.re/badge-flat.svg)](https://awesome.re)

**NOTE** - This is a work in progress. Changes and additions are welcome. Please use Pull Requests to suggest modifications and improvements. 

A curated list of resources to help you become a Generative AI (GenAI) Developer. This repository includes resources on building GenAI applications with Large Language Models (LLMs), and deploying LLMs and GenAI with Cloud-based solutions.

## Contents:

- [Python Libraries (GenAI and LLMs)](#python-libraries-genai-and-llms)
- [Projects (GenAI and LLMs)](#llm-deployment-cloud-services)
- [Courses](#courses-genai-and-llms)

Comming Soon:

- Communities
- Social
- Books

# Python Libraries (GenAI and LLMs)

## AI LLM Frameworks

- [LangChain](https://github.com/langchain-ai/langchain): A framework for developing applications powered by large language models (LLMs).
- [LangGraph](https://github.com/langchain-ai/langgraph): A library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.
- [LlamaIndex](https://github.com/run-llama/llama_index): LlamaIndex is a framework for building context-augmented generative AI applications with LLMs.
- [LlamaIndex Workflows](https://www.llamaindex.ai/blog/introducing-workflows-beta-a-new-way-to-create-complex-ai-applications-with-llamaindex): LlamaIndex workflows is a mechanism for orchestrating actions in the increasingly-complex AI application we see our users building.

## LLM Models

- [OpenAI](https://github.com/openai/openai-python): The official Python library for the OpenAI API
- [Hugging Face Models](https://huggingface.co/models): Open LLM models by Meta, Mistral, and hundreds of other providers
- [Anthropic Claude](https://github.com/anthropics/anthropic-sdk-python): The official Python library for the Anthropic API
- [Meta Llama Models](https://llama.meta.com/): The open source AI model you can fine-tune, distill and deploy anywhere.
- [Google Gemini](https://github.com/google-gemini/generative-ai-python): The official Python library for the Google Gemini API
- [Ollama](https://github.com/ollama/ollama): Get up and running with large language models locally.
- [Grok](https://github.com/groq/groq-python): The official Python Library for the Groq API

## Vector Databases (RAG)

- [ChromaDB](https://github.com/chroma-core/chroma): The fastest way to build Python or JavaScript LLM apps with memory!
- [FAISS](https://github.com/facebookresearch/faiss): A library for efficient similarity search and clustering of dense vectors.
- [Pinecone](https://github.com/pinecone-io/pinecone-python-client): The official Pinecone Python SDK.
- [Milvus](https://github.com/milvus-io/milvus): Milvus is an open-source vector database built to power embedding similarity search and AI applications. 

# LLM Deployment (Cloud Services)

- [AWS Bedrock](https://aws.amazon.com/bedrock/)
- [Microsoft Azure AI Services](https://azure.microsoft.com/en-us/products/ai-services)
- [Google Vertex AI](https://cloud.google.com/vertex-ai)
- [NVIDIA NIM](https://www.nvidia.com/en-us/ai)


# Projects (GenAI and LLMs)

## Cookbooks and Examples:

- [LangChain Cookbook](https://github.com/langchain-ai/langchain/blob/master/cookbook/README.md): Example code for building applications with LangChain, with an emphasis on more applied and end-to-end examples.
- [LangGraph Examples](https://github.com/langchain-ai/langgraph/tree/main/examples): Example code for building applications with LangGraph
- [Llama Index Examples](https://github.com/run-llama/llama_index/tree/main/docs/docs/examples): Example code for building applications with Llama Index
- [Streamlit LLM Examples](https://github.com/streamlit/llm-examples): Streamlit LLM app examples for getting started

## Cloud Examples:

- [Azure Generative AI Examples](https://github.com/Azure/azureml-examples/tree/main/sdk/python/generative-ai): Prompt Flow and RAG Examples for use with the Microsoft Azure Cloud platform
- [Amazon Bedrock Workshop](https://github.com/aws-samples/amazon-bedrock-workshop): Introduces how to leverage foundation models (FMs) through Amazon Bedrock
- [Google Vertex AI Examples](https://github.com/GoogleCloudPlatform/vertex-ai-samples): Notebooks, code samples, sample apps, and other resources that demonstrate how to use, develop and manage machine learning and generative AI workflows using Google Cloud Vertex AI
- [NVIDIA NIM Anywhere](https://github.com/NVIDIA/nim-anywhere): An entrypoint for developing with NIMs that natively scales out to full-sized labs and up to production environments.
- [NVIDIA NIM Deploy](https://github.com/NVIDIA/nim-deploy): Reference implementations, example documents, and architecture guides that can be used as a starting point to deploy multiple NIMs and other NVIDIA microservices into Kubernetes and other production deployment environments.


# Courses (GenAI and LLMs)

## 8-Week AI Bootcamp by Business Science

We are launching a new Generative AI Bootcamp that covers end-to-end AI application development and Cloud deployment. [Find out more about how to build AI with Python, and attend our free AI training session here.](https://learn.business-science.io/registration-ai-workshop-2)
